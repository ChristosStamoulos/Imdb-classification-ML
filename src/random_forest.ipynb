{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ανάλυση IMDB δεδομένων\n",
    "### Random Forest Ταξινομητής\n",
    "\n",
    "Ορίζουμε τις **υπερπαραμέτρους** που θα χρησιμοποιηθούν για την ανάπλαση των δωσμένων δεδομένων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3000   # Πλήθος λέξεων του λεξιλογίου\n",
    "n = 50     # Πιο συχνές λέξεις για παράληψη\n",
    "k = 1000   # Λιγότερο συχνές λέξεις για παράληψη"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αντλούμε τα δεδομένα από τη βάση δεδομένων IMDB, αγνοώντας τις πιο συχνά χρησιμοποιούμενες λέξεις n και τις λιγότερες χρησιμοποιούμενες λέξεις k. (υπερπαράμετροι)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shina\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from math import log \n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=m-k, skip_top=n)\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
    "index2word[0] = '[pad]'\n",
    "index2word[1] = '[bos]'\n",
    "index2word[2] = '[oov]'\n",
    "\n",
    "x_train = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train])\n",
    "x_test = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Δημιουργία δυαδικών διανυσμάτων"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μετατρέπουμε τα αντλημένα δεδομένα σε δυαδικά διανύσματα. Οι δυνατές τιμές είναι 0 και 1. Τιμή 1 συνεπάγεται ότι η αντίστοιχη λέξη περιέχεται στο κείμενο, ενώ τιμή 0 συνεπάγεται ότι δεν περιέχεται."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1906\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "binary_vectorizer = CountVectorizer(binary=True)\n",
    "x_train_binary = binary_vectorizer.fit_transform(x_train)\n",
    "x_test_binary = binary_vectorizer.transform(x_test)\n",
    "\n",
    "x_train_binary = np.array(x_train_binary.toarray())\n",
    "x_test_binary = np.array(x_test_binary.toarray())\n",
    "print(\n",
    "    'Vocabulary size:', len(binary_vectorizer.vocabulary_)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Χ είναι ένας πίνακας διανυσμάτων (αξιολογήσεων), με κάθε διάνυσμα να αναπαριστά λέξεις. Y είναι ένα διάνυσμα με ετικέτες (0 ή 1) όπου 0 είναι μια αρνητική αξιολόγηση και 1 μια θετική."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$X = \\begin{bmatrix} \\vec{x_{1}} \\\\ \\vdots \\\\ \\vec{x_{m}} \\end{bmatrix}\\, \\, \\, \n",
    "y = \\begin{bmatrix} y_{1} \\\\ \\vdots \\\\ y_{m} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Υλοποίηση του Random Forest Ταξινομητή"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Κλάση που υλοποιεί τον Random Forest Ταξινομητή. Η κλαση αποτελείται από δύο βασικές μεθόδους, την fit και την predict. Η μέθοδος fit εκπαιδεύει τον αλγόριθμο χρησιμόποιώντας τον πίνακα των δυαδικών διανυσμάτων X και τον πίνακα με τις ετικέτες y. Η μέθοδος predict δέχεται ένα πίνακα διανυσμάτων και επιστρέφει ένα προβλεπόμενο διάνυσμα με ετικέτες."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "import numpy as np\n",
    "from id3 import ID3\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, m, num_of_trees, max_depth=5):\n",
    "        self.m = m\n",
    "        self.num_of_trees = num_of_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.random_trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.random_trees.clear()\n",
    "        print(\"Starting fitting process\")\n",
    "\n",
    "        for i in range(self.num_of_trees):\n",
    "            print(f\"Fitting tree {i + 1}/{self.num_of_trees}\")\n",
    "            random_x, random_y = self.select_random_samples(X, y)\n",
    "\n",
    "            if len(random_x) > 0:\n",
    "                print(f\"Random samples: {random_x.shape}\")\n",
    "                random_features = self.select_random_features(random_x)\n",
    "                id3 = ID3(random_features)#self.max_depth)\n",
    "                tree = id3.fit(random_x, random_y)\n",
    "                \n",
    "                if tree is not None:  # Check if a valid tree is returned\n",
    "                    print(f\"Tree {i + 1} fitted successfully\")\n",
    "                    self.random_trees.append(id3)\n",
    "                else:\n",
    "                    print(f\"Skipping tree {i + 1} due to empty data or other issues.\")\n",
    "            else:\n",
    "                print(f\"Skipping tree {i + 1} due to empty data.\")\n",
    "\n",
    "        print(\"Fitting process completed\")\n",
    "\n",
    "    def select_random_samples(self, X, y):\n",
    "        x_sample = list()\n",
    "        y_sample = list()\n",
    "        indices = np.arange(len(y))\n",
    "\n",
    "        for i in range(len(y)):\n",
    "            random_choice = np.random.choice(indices)\n",
    "            x_sample.append(X[random_choice])\n",
    "            y_sample.append(y[random_choice])\n",
    "\n",
    "        x_sample = np.array(x_sample)\n",
    "        y_sample = np.array(y_sample)   \n",
    "\n",
    "        return x_sample, y_sample\n",
    "\n",
    "    def select_random_features(self, random_x):\n",
    "        indices = np.arange(len(random_x[0]))\n",
    "        random_feature_indices = np.random.choice(indices, self.m, replace=False)\n",
    "\n",
    "        return random_feature_indices\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        total = list()\n",
    "        \n",
    "        for tree in self.random_trees:\n",
    "            categories = tree.predict(X)\n",
    "            total.append(np.array(categories))\n",
    "\n",
    "        for i in range(0, X.shape[0]):################ \n",
    "            num1 = 0\n",
    "            num0 = 0\n",
    "            for category in total:\n",
    "                if(category[i] == 1):\n",
    "                    num1 +=1\n",
    "                else:\n",
    "                    num0 +=1\n",
    "            if num1 > num0:\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(0)\n",
    "\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualizations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = classification_data(RandomForest(200, num_of_trees = 3), x_train_binary, y_train, x_test_binary, y_test, 5)\n",
    "\n",
    "print(classification_report(y_test, data['test_predictions']))\n",
    "data_table = classification_table(data, x_train_binary)\n",
    "ipd.display(data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForest(200, num_of_trees = 3)\n",
    "rf.fit(x_train_binary, y_train)\n",
    "print(classification_report(y_train, rf.predict(x_train_binary),\n",
    "                            zero_division=1))\n",
    "print(classification_report(y_test, rf.predict(x_test_binary),\n",
    "                            zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(criterion='entropy', max_depth=5, max_features=200)\n",
    "rf.fit(x_train_binary, y_train)\n",
    "print(classification_report(y_train, rf.predict(x_train_binary),\n",
    "                            zero_division=1))\n",
    "print(classification_report(y_test, rf.predict(x_test_binary),\n",
    "                            zero_division=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
