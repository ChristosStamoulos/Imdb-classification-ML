{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\stamc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2500   \n",
    "n = 200    \n",
    "k = 0      \n",
    "\n",
    "\n",
    "(x_train_imdb, y_train_imdb), (x_test_imdb, y_test_imdb) = tf.keras.datasets.imdb.load_data(num_words=m-k, skip_top=n)\n",
    "\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
    "index2word[0] = '[pad]'\n",
    "index2word[1] = '[bos]'\n",
    "index2word[2] = '[oov]'\n",
    "x_train_imdb = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train_imdb])\n",
    "x_test_imdb = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test_imdb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2260\n"
     ]
    }
   ],
   "source": [
    "binary_vectorizer = CountVectorizer(binary=True)\n",
    "x_train_imdb_binary = binary_vectorizer.fit_transform(x_train_imdb)\n",
    "x_test_imdb_binary = binary_vectorizer.transform(x_test_imdb)\n",
    "print(\n",
    "    'Vocabulary size:', len(binary_vectorizer.vocabulary_)\n",
    ")\n",
    "\n",
    "x_train_imdb_binary = x_train_imdb_binary.toarray()\n",
    "x_test_imdb_binary = x_test_imdb_binary.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, lambda_value = 0.001, max_iter = 100):\n",
    "        self.lambda_value = lambda_value\n",
    "        self.max_iter = max_iter\n",
    "        self.weights = None\n",
    "        self.regularization = 0\n",
    "        self.eta = 0.01\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        samples = X.shape[0]\n",
    "        features = X.shape[1]\n",
    "        self.weights = np.zeros(features)\n",
    "\n",
    "        for t in range(self.max_iter):\n",
    "            linear = np.dot(X, self.weights) + self.regularization\n",
    "            y_pred = self.sigmoid(linear)\n",
    "\n",
    "            gradient_ascent = np.dot(X.T, (y_pred - y)) * (1 / samples) \n",
    "            loss = np.sum(y_pred - y) * (1 / samples)\n",
    "\n",
    "            self.weights -= self.eta * gradient_ascent\n",
    "            self.regularization -= self.lambda_value * loss\n",
    "           \n",
    "    def predict(self, X):\n",
    "        linear = np.dot(X, self.weights) + self.regularization\n",
    "        y_pred = self.sigmoid(linear)\n",
    "        y_pred_classes = [1 if i>0.5 else 0 for i in y_pred]\n",
    "        return y_pred_classes\n",
    "    \n",
    "    def sigmoid(self, t):\n",
    "        return 1 / (1 + np.exp(-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83     12500\n",
      "           1       0.84      0.81      0.82     12500\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.83      0.83      0.83     25000\n",
      "weighted avg       0.83      0.83      0.83     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "\n",
    "log.fit(x_train_imdb_binary, y_train_imdb)\n",
    "print(classification_report(y_test_imdb,log.predict(x_test_imdb_binary)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stamc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85     12500\n",
      "           1       0.85      0.86      0.85     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Algorithm to use in the optimization problem.\n",
    "#Each solver tries to find the parameter weights that minimize a cost function\n",
    "log = LogisticRegression()\n",
    "log.fit(x_train_imdb_binary, y_train_imdb)\n",
    "print(classification_report(y_test_imdb, log.predict(x_test_imdb_binary)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
