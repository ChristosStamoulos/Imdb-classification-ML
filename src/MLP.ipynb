{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilevel Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eleni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_imdb, y_train_imdb), (x_test_imdb, y_test_imdb) = tf.keras.datasets.imdb.load_data()\n",
    "\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
    "index2word[0] = '[pad]'\n",
    "index2word[1] = '[bos]'\n",
    "index2word[2] = '[oov]'\n",
    "x_train_imdb = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train_imdb])\n",
    "x_test_imdb = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test_imdb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 3834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# min-df --> when building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.\n",
    "binary_vectorizer = CountVectorizer(binary=True, min_df=100)\n",
    "x_train_imdb_binary = binary_vectorizer.fit_transform(x_train_imdb)\n",
    "x_test_imdb_binary = binary_vectorizer.transform(x_test_imdb)\n",
    "print(\n",
    "    'Vocabulary size:', len(binary_vectorizer.vocabulary_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_imdb_binary = x_train_imdb_binary.toarray()\n",
    "x_test_imdb_binary = x_test_imdb_binary.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eleni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.04668405,  0.00094485,  0.01560987, -0.00757938,  0.01854808],\n",
       "       [ 0.01599525, -0.00434742, -0.00332546,  0.01437619, -0.02622013],\n",
       "       [ 0.03637208,  0.04453986, -0.00845218,  0.01072422,  0.03666883]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_embeddings = tf.keras.layers.Embedding(1000, 5)\n",
    "dummy_embeddings(tf.constant([1, 2, 3])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 9ms/step - loss: 0.5061 - accuracy: 0.7874\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3149 - accuracy: 0.8799\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.2605 - accuracy: 0.8994\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.2366 - accuracy: 0.9082\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3003 - accuracy: 0.8783\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(3834,)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_imdb_binary, y_train_imdb, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test_imdb_binary, y_test_imdb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
