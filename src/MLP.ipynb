{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilevel Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eleni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_imdb, y_train_imdb), (x_test_imdb, y_test_imdb) = tf.keras.datasets.imdb.load_data()\n",
    "\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
    "index2word[0] = '[pad]'\n",
    "index2word[1] = '[bos]'\n",
    "index2word[2] = '[oov]'\n",
    "x_train_imdb = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train_imdb])\n",
    "x_test_imdb = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test_imdb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 3834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# min-df --> when building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.\n",
    "binary_vectorizer = CountVectorizer(binary=True, min_df=100)\n",
    "x_train_imdb_binary = binary_vectorizer.fit_transform(x_train_imdb)\n",
    "x_test_imdb_binary = binary_vectorizer.transform(x_test_imdb)\n",
    "print(\n",
    "    'Vocabulary size:', len(binary_vectorizer.vocabulary_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_imdb_binary = x_train_imdb_binary.toarray()\n",
    "x_test_imdb_binary = x_test_imdb_binary.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
