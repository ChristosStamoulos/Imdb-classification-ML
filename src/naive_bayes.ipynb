{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB analysis with scikit-learn & custom algorithms\n",
    "### Naive Bayes Classifier\n",
    "\n",
    "Ορίζουμε τις υπερπαραμέτρους που απαιτούνται για τα δεδομένα που θα χρησιμοποιήσουμε παρακάτω."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2500   # Number of words in the vocabulary\n",
    "n = 200    # N most frequent words to skip\n",
    "k = 0      # K least frequent words to skip\n",
    "\n",
    "infogain = False\n",
    "g = 800 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παίρνουμε τα δεδομένα από τη βάση δεδομένων του IMDB, αγνοώντας τις πιο συχνά χρησιμοποιούμενες λέξεις n και τις λιγότερες χρησιμοποιούμενες λέξεις k. \n",
    "\n",
    "(Είναι οι υπερπαράμετροι που ορίσαμε παραπάνω.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eleni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from math import log \n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=m-k, skip_top=n)\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
    "index2word[0] = '[pad]'\n",
    "index2word[1] = '[bos]'\n",
    "index2word[2] = '[oov]'\n",
    "\n",
    "x_train = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train])\n",
    "x_test = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Vector Creation\n",
    "Τροποποιούμε τα δεδομένα που πήραμε έτσι ώστε να γίνουν δυαδικά διανύσματα. Τα διανύσματα αυτά αποτελούνται απο 0 και 1, με 1 να σημαίνει ότι η λέξη υπάρχει στο κείμενο, ενώ με 0 δεν υπάρχει."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "binary_vectorizer = CountVectorizer(binary=True)\n",
    "x_train_binary = binary_vectorizer.fit_transform(x_train)\n",
    "x_test_binary = binary_vectorizer.transform(x_test)\n",
    "\n",
    "x_train_binary = np.array(x_train_binary.toarray())\n",
    "x_test_binary = np.array(x_test_binary.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Χ είναι ένας πίνακας διανυσμάτων (αξιολογήσεων), με κάθε διάνυσμα να αναπαριστά λέξεις. \n",
    "Y είναι ένα διάνυσμα με ετικέτες (0 ή 1) όπου 0 είναι μια αρνητική αξιολόγηση και 1 μια θετική.\n",
    "\n",
    "$$X = \\begin{bmatrix} \\vec{x_{1}} \\\\ \\vdots \\\\ \\vec{x_{m}} \\end{bmatrix}\\, \\, \\, \n",
    "y = \\begin{bmatrix} y_{1} \\\\ \\vdots \\\\ y_{m} \\end{bmatrix}$$\n",
    "\n",
    "### Κέρδος Πληροφορίας\n",
    "Είναι κώδικας από τα εργαστήρια. Επιστρέφει τις g λέξεις με το μεγαλύτερο κέρδος πληροφορίας από το σύνολο δεδομένων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log \n",
    "\n",
    "if infogain:\n",
    "  def IG(class_, feature):\n",
    "    classes = set(class_)\n",
    "\n",
    "    Hc = 0\n",
    "    for c in classes:\n",
    "      pc = list(class_).count(c)/len(class_)\n",
    "      Hc += - pc * log(pc, 2)\n",
    "    feature_values = set(feature)\n",
    "\n",
    "    Hc_feature = 0 # Αρχικοποίηση της εντροπίας του χαρακτηριστικού Hc_feature.\n",
    "    for feat in feature_values:\n",
    "      \n",
    "      # Υπολογισμός του P(X=x)\n",
    "      pf = list(feature).count(feat)/len(feature)\n",
    "      indices = [i for i in range(len(feature)) if feature[i] == feat]\n",
    "      clasess_of_feat = [class_[i] for i in indices]\n",
    "      for c in classes:\n",
    "          # Υπολογισμός του P(C=c|X=x)\n",
    "          pcf = clasess_of_feat.count(c)/len(clasess_of_feat)\n",
    "          if pcf != 0: \n",
    "              # Υπολογισμός του - P(X=x) * P(C=c|X=x) * log2(P(C=c|X=x))\n",
    "              temp_H = - pf * pcf * log(pcf, 2)\n",
    "              #sum for all values of C (class) and X (values of specific feature)\n",
    "              Hc_feature += temp_H\n",
    "    # Υπολογισμός του information gain.\n",
    "    ig = Hc - Hc_feature\n",
    "    return ig\n",
    "\n",
    "  # Επιλογή των g πιο σημαντικών χαρακτηριστικών.\n",
    "  ig = [(i, IG(y_train, x_train_binary[:, i])) for i in range(len(x_train_binary[0]))]\n",
    "  ig.sort(key=lambda x: x[1], reverse=True)\n",
    "  ig = ig[:g]\n",
    "  # Προσαρμογή των δεδομένων εκπαίδευσης και ελέγχου.\n",
    "  x_train_binary = x_train_binary[:, [i[0] for i in ig]]\n",
    "  x_test_binary = x_test_binary[:, [i[0] for i in ig]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes Classifier Implementation\n",
    "Κλάση που υλοποιεί τον Bernoulli Naive Bayes Classifier. Η κλαση έχει δύο μεθόδους train και predict. Η μέθοδος train εκπαιδεύει τον αλγόριθμο χρησιμόποιώντας ένα πίνακα διανυσμάτων x που δίνεται. Η μέθοδος predict δέχεται ένα πίνακα διανυσμάτων και επιστρέφει ένα διάνυσμα με ετικέτες.\n",
    "\n",
    "Χρησιμοποιούμε και εκτιμήτρια Laplace για την εξομάλυνση πιθανοτήτων και την αποφυγή μηδενικών εκτιμήσεων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernoulliNaiveBayes:\n",
    "  \n",
    "  def __init__(self):\n",
    "    pass \n",
    "\n",
    "  def fit(self, x, y):\n",
    "    all_positive = np.sum(y)\n",
    "    all_texts = len(y)\n",
    "\n",
    "    # Υπολογισμός της (log) πιθανότητας για κάθε κλάση\n",
    "    self.positive = np.log(all_positive / all_texts)\n",
    "    self.negative = np.log(1 - all_positive / len(y))\n",
    "    \n",
    "    # Υπολογισμός (log) πιθανότητας για κάθε σύνολο χαρακτηριστικών δεδομένα κάθε κλάσης (y = 1 ή y = 0)\n",
    "    # p(feature|class) = (np.sum(X[y == class], axis=0) + 1) / (np.sum(y) + 2)\n",
    "    self.positive_1 = np.log((np.sum(x[y == 1], axis=0) + 1) / (all_positive + 2))\n",
    "    self.negative_1 = np.log((np.sum(x[y == 0], axis=0) + 1) / (all_texts - all_positive + 2))\n",
    "    self.positive_0 = np.log(1.0 - (np.sum(x[y == 1], axis=0) + 1) / (all_positive + 2))\n",
    "    self.negative_0 = np.log(1.0 - (np.sum(x[y == 0], axis=0) + 1) / (all_texts - all_positive + 2))\n",
    "    \n",
    "    \n",
    "  def predict(self, x):\n",
    "    # Υπολογισμός των (log) πιθανοτήτων για κάθε κλάση\n",
    "    positive = x.dot(self.positive_0) + x.dot(self.positive_1) + self.positive\n",
    "    negative = x.dot(self.negative_0) + x.dot(self.negative_1) + self.negative\n",
    "    # Καθορισμός της πρόβλεψης βάσει των (log) πιθανοτήτων\n",
    "    return np.array([1 if positive[i] > negative[i] else 0 for i in range(len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualizations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes Classifier Results and Comparison\n",
    "\n",
    "Ο Naive Bayes Classifier εξετάζεται στα test δεδομένα και τα αποτελέσματα φαίνονται στον πίνακα παρακάτω. Επίσης γίνεται και μια σύγκριση μεταξύ των αποτελεσμάτων πρόβλεψης των δεδομένων εκπαίδευσης και των δεδομένων προς εξέταση. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84     12500\n",
      "           1       0.84      0.85      0.84     12500\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.84      0.84      0.84     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision Train</th>\n",
       "      <th>Precision Test</th>\n",
       "      <th>Recall Train</th>\n",
       "      <th>Recall Test</th>\n",
       "      <th>F1 Train</th>\n",
       "      <th>F1 Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Train Accuracy  Test Accuracy  Precision Train  Precision Test  \\\n",
       "5000             0.87           0.84             0.85            0.82   \n",
       "10000            0.86           0.84             0.86            0.84   \n",
       "15000            0.86           0.84             0.84            0.83   \n",
       "20000            0.85           0.84             0.83            0.82   \n",
       "25000            0.85           0.84             0.84            0.84   \n",
       "\n",
       "       Recall Train  Recall Test  F1 Train  F1 Test  \n",
       "5000           0.91         0.87      0.88     0.84  \n",
       "10000          0.87         0.84      0.87     0.84  \n",
       "15000          0.88         0.85      0.86     0.84  \n",
       "20000          0.89         0.87      0.86     0.84  \n",
       "25000          0.87         0.85      0.85     0.84  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = classification_data(BernoulliNaiveBayes(), x_train_binary, y_train, x_test_binary, y_test, 5)\n",
    "\n",
    "print(classification_report(y_test, data['test_predictions']))\n",
    "data_table = classification_table(data)\n",
    "ipd.display(data_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes against SKLearn's Bernoulli Naive Bayes\n",
    "\n",
    "Ο Bernoulli Naive Bayes εξετάζεται ενάντια στον Bernoulli Naive Bayes της βιβλιοθήκης SKLearn. Τα αποτελέσματα φαίνονται παρακάτω στον πίνακα και όπως περιμέναμε είναι όμοια. (Παρακάτω φαίνεται η διαφορά μεταξύ των αποτελεσμάτων που έδωσε κάθε αλγόριθμος)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_18c66\">\n",
       "  <caption>Classification Table Difference for BernoulliNaiveBayes against SKBernoulliNB</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_18c66_level0_col0\" class=\"col_heading level0 col0\" >Train Accuracy</th>\n",
       "      <th id=\"T_18c66_level0_col1\" class=\"col_heading level0 col1\" >Test Accuracy</th>\n",
       "      <th id=\"T_18c66_level0_col2\" class=\"col_heading level0 col2\" >Precision Train</th>\n",
       "      <th id=\"T_18c66_level0_col3\" class=\"col_heading level0 col3\" >Precision Test</th>\n",
       "      <th id=\"T_18c66_level0_col4\" class=\"col_heading level0 col4\" >Recall Train</th>\n",
       "      <th id=\"T_18c66_level0_col5\" class=\"col_heading level0 col5\" >Recall Test</th>\n",
       "      <th id=\"T_18c66_level0_col6\" class=\"col_heading level0 col6\" >F1 Train</th>\n",
       "      <th id=\"T_18c66_level0_col7\" class=\"col_heading level0 col7\" >F1 Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_18c66_level0_row0\" class=\"row_heading level0 row0\" >5000</th>\n",
       "      <td id=\"T_18c66_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "      <td id=\"T_18c66_row0_col1\" class=\"data row0 col1\" >0.010000</td>\n",
       "      <td id=\"T_18c66_row0_col2\" class=\"data row0 col2\" >0.030000</td>\n",
       "      <td id=\"T_18c66_row0_col3\" class=\"data row0 col3\" >0.030000</td>\n",
       "      <td id=\"T_18c66_row0_col4\" class=\"data row0 col4\" >0.050000</td>\n",
       "      <td id=\"T_18c66_row0_col5\" class=\"data row0 col5\" >0.060000</td>\n",
       "      <td id=\"T_18c66_row0_col6\" class=\"data row0 col6\" >0.010000</td>\n",
       "      <td id=\"T_18c66_row0_col7\" class=\"data row0 col7\" >0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18c66_level0_row1\" class=\"row_heading level0 row1\" >10000</th>\n",
       "      <td id=\"T_18c66_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "      <td id=\"T_18c66_row1_col1\" class=\"data row1 col1\" >0.000000</td>\n",
       "      <td id=\"T_18c66_row1_col2\" class=\"data row1 col2\" >0.010000</td>\n",
       "      <td id=\"T_18c66_row1_col3\" class=\"data row1 col3\" >0.010000</td>\n",
       "      <td id=\"T_18c66_row1_col4\" class=\"data row1 col4\" >0.010000</td>\n",
       "      <td id=\"T_18c66_row1_col5\" class=\"data row1 col5\" >0.010000</td>\n",
       "      <td id=\"T_18c66_row1_col6\" class=\"data row1 col6\" >0.000000</td>\n",
       "      <td id=\"T_18c66_row1_col7\" class=\"data row1 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18c66_level0_row2\" class=\"row_heading level0 row2\" >15000</th>\n",
       "      <td id=\"T_18c66_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "      <td id=\"T_18c66_row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
       "      <td id=\"T_18c66_row2_col2\" class=\"data row2 col2\" >0.020000</td>\n",
       "      <td id=\"T_18c66_row2_col3\" class=\"data row2 col3\" >0.020000</td>\n",
       "      <td id=\"T_18c66_row2_col4\" class=\"data row2 col4\" >0.030000</td>\n",
       "      <td id=\"T_18c66_row2_col5\" class=\"data row2 col5\" >0.030000</td>\n",
       "      <td id=\"T_18c66_row2_col6\" class=\"data row2 col6\" >0.000000</td>\n",
       "      <td id=\"T_18c66_row2_col7\" class=\"data row2 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18c66_level0_row3\" class=\"row_heading level0 row3\" >20000</th>\n",
       "      <td id=\"T_18c66_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "      <td id=\"T_18c66_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
       "      <td id=\"T_18c66_row3_col2\" class=\"data row3 col2\" >0.030000</td>\n",
       "      <td id=\"T_18c66_row3_col3\" class=\"data row3 col3\" >0.030000</td>\n",
       "      <td id=\"T_18c66_row3_col4\" class=\"data row3 col4\" >0.050000</td>\n",
       "      <td id=\"T_18c66_row3_col5\" class=\"data row3 col5\" >0.050000</td>\n",
       "      <td id=\"T_18c66_row3_col6\" class=\"data row3 col6\" >0.010000</td>\n",
       "      <td id=\"T_18c66_row3_col7\" class=\"data row3 col7\" >0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_18c66_level0_row4\" class=\"row_heading level0 row4\" >25000</th>\n",
       "      <td id=\"T_18c66_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "      <td id=\"T_18c66_row4_col1\" class=\"data row4 col1\" >0.000000</td>\n",
       "      <td id=\"T_18c66_row4_col2\" class=\"data row4 col2\" >0.010000</td>\n",
       "      <td id=\"T_18c66_row4_col3\" class=\"data row4 col3\" >0.010000</td>\n",
       "      <td id=\"T_18c66_row4_col4\" class=\"data row4 col4\" >0.020000</td>\n",
       "      <td id=\"T_18c66_row4_col5\" class=\"data row4 col5\" >0.020000</td>\n",
       "      <td id=\"T_18c66_row4_col6\" class=\"data row4 col6\" >0.000000</td>\n",
       "      <td id=\"T_18c66_row4_col7\" class=\"data row4 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x131636b2cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bayes_data = classification_data(BernoulliNB(), x_train_binary, y_train, x_test_binary, y_test, 5)\n",
    "bayes_data['estimator'] = 'SKBernoulliNB'\n",
    "bayes_table = classification_table(bayes_data)\n",
    "difference_table = abs(bayes_table - data_table)\n",
    "difference_table = difference_table.style.set_caption('Classification Table Difference for {estimator} against {estimator_2}'.format(estimator=data['estimator'], estimator_2=bayes_data['estimator']))\n",
    "ipd.display(difference_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
